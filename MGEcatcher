#!/bin/bash

set -e

#usage
usage() {
USAGE="
                              ███╗   ███╗ ██████╗ ███████╗             
                              ████╗ ████║██╔════╝ ██╔════╝             
                              ██╔████╔██║██║  ███╗█████╗               
                              ██║╚██╔╝██║██║   ██║██╔══╝               
                              ██║ ╚═╝ ██║╚██████╔╝███████╗             
                              ╚═╝     ╚═╝ ╚═════╝ ╚══════╝             
               ██████╗ █████╗ ████████╗ ██████╗██╗  ██╗███████╗██████╗ 
              ██╔════╝██╔══██╗╚══██╔══╝██╔════╝██║  ██║██╔════╝██╔══██╗
              ██║     ███████║   ██║   ██║     ███████║█████╗  ██████╔╝
              ██║     ██╔══██║   ██║   ██║     ██╔══██║██╔══╝  ██╔══██╗
              ╚██████╗██║  ██║   ██║   ╚██████╗██║  ██║███████╗██║  ██║
               ╚═════╝╚═╝  ╚═╝   ╚═╝    ╚═════╝╚═╝  ╚═╝╚══════╝╚═╝  ╚═╝

══════════════════════════════════════════════════════════════════════════════════
                 Automated pipeline to identify mobile genetic elements 
                          in long read DNA sequencing data
----------------------------------------------------------------------------------
                          by: Vinícius Franceschini-Santos, 2022
══════════════════════════════════════════════════════════════════════════════════

\e[4mUsage\e[0m:

MGEcatcher --reads <reads.fq> --mge_seed <mge.fa> [--threads <N>] \\
           --output <path/to/output/> --prefix <BC01>

\e[4mRequired arguments\e[0m:
     --reads        Fastq file for basecalled reads to be used as subject

     --mge_seed     Fasta file containing MGE sequences to be used as query

     --output       Output dir name; will be created if does not exist

     --prefix       Barcode identifier (ex.: BC01)

\e[4mOptional arguments\e[0m:
     --threads      Number of threads (default: 10)

"
echo -e "$USAGE"
exit 2
}

# error function
error_exit() {
        msg=$1
        exit_code=${2:-1}
        echo -e "\033[1;31m${msg}\033[0m"
        usage
}

# thanks, stackoverflow!
join_path() {
    echo "${1:+$1/}$2" | sed 's#//#/#g'
}

check_deps() {
    for app in blastn bedtools; do
        command -v $CONDA_PREFIX/bin/$app >/dev/null 2>&1 || error_exit \
                "ERROR: Cannot find ${app}. Make sure it is installed and in your PATH variable"
    done
}


VERSION=0.2
check_deps


HOME_DIR=${0%/*}
# Log message function (normal text)
log() {
	printf '[ %(%y-%m-%d %H:%M:%S)T ] '
	printf "%*s\n" 60 "$1"
}
# Warning message function (yellow text)
warn() {
	printf "\033[1;33mWARNING:%*s\033[0m\n" 75 "$1"
	}
# "Done" message function
DONEmsg() {
	printf '[ %(%y-%m-%d %H:%M:%S)T] '
	printf "%*s\n" 61 "Done!"
}
# parse args

THREADS=10
# option strings
SHORT=h
LONG=help,reads:,prefix:,mge_seed:,output:,threads:

# read the options
OPTS=$(getopt --options $SHORT --long $LONG --name "$0" -- "$@")
if [ $? != 0 ] ; then echo "Failed to parse options...exiting." ; exit 1 ; fi
eval set -- "$OPTS"
while true ; do
  case "$1" in
    -h | --help )
      usage
      ;;
    --reads )
      READS="$2"
      shift 2
	 ;;
    --threads )
      THREADS="$2"
      shift 2
	 ;;
    --mge_seed )
       MGE="$2"
      shift 2
	 ;;
    --output )
       OUTPUT="$2"
      shift 2
	 ;;
    --prefix )
      PREFIX="$2"
     shift 2
	 ;;
    -- )
     shift
     break
     ;;
    *)
     error_exit "ERROR: Please, supply required arguments correctly."
     ;;
 esac
done


declare -A array # associative arrays need to be declared!
array=( [--reads]="${READS}" [--mge_seed]="${MGE}" \
		[--output]="${OUTPUT}" [--prefix]="${PREFIX}" \
		[--threads]="${THREADS}")

for idx in "${!array[@]}"; do
	if [[ ! ${array[$idx]} ]]; then
	echo "ERROR: $idx argument must be supplied. ${array[$idx]} exiting..."
	usage
	fi
done


echo "
                             ███╗   ███╗ ██████╗ ███████╗             
                             ████╗ ████║██╔════╝ ██╔════╝             
                             ██╔████╔██║██║  ███╗█████╗               
                             ██║╚██╔╝██║██║   ██║██╔══╝               
                             ██║ ╚═╝ ██║╚██████╔╝███████╗             
                             ╚═╝     ╚═╝ ╚═════╝ ╚══════╝             
              ██████╗ █████╗ ████████╗ ██████╗██╗  ██╗███████╗██████╗ 
             ██╔════╝██╔══██╗╚══██╔══╝██╔════╝██║  ██║██╔════╝██╔══██╗
             ██║     ███████║   ██║   ██║     ███████║█████╗  ██████╔╝
             ██║     ██╔══██║   ██║   ██║     ██╔══██║██╔══╝  ██╔══██╗
             ╚██████╗██║  ██║   ██║   ╚██████╗██║  ██║███████╗██║  ██║
              ╚═════╝╚═╝  ╚═╝   ╚═╝    ╚═════╝╚═╝  ╚═╝╚══════╝╚═╝  ╚═╝

══════════════════════════════════════════════════════════════════════════════════
                Automated pipeline to identify mobile genetic elements 
                          in long read DNA sequencing data
----------------------------------------------------------------------------------
                       by: Vinícius Franceschini-Santos, 2021
══════════════════════════════════════════════════════════════════════════════════"
printf "%s%*s\n" "Reads:" 76 "${READS}"
printf "%s%*s\n" "MGE seed:" 73 "${MGE}"
printf "%s%*s\n" "Output dir:" 71 "${OUTPUT}" 
printf "%s%*s\n" "Threads:" 74 "${THREADS}"
printf "%s%*s\n" "Prefix:" 75 "${PREFIX}"
echo "══════════════════════════════════════════════════════════════════════════════════"
# make temp files
mkdir -p ${OUTPUT}
mkdir -p ${OUTPUT}/tmp/

READ_BNAME=`basename ${READS}`

FASTA=${OUTPUT}/tmp/${READ_BNAME%.*}.fasta

if [ ! -f ${FASTA} ]; then
	log "Converting input reads to fasta"
	sed -n '1~4s/^@/>/p;2~4p' ${READS} > ${FASTA}

else
	warn "File ${FASTA} already exists. Skipping"
fi

if [ ! -f ${FASTA}.nsq ]; then
	log "Creating database for BLAST"
	$CONDA_PREFIX/bin/makeblastdb -in ${FASTA} \
		-dbtype nucl > /dev/null 2> /dev/null

else
	warn "Blast database already exists. Skipping"
fi

MAPPINGOUT=${OUTPUT}/tmp/${READ_BNAME%.*}.MGE-mapping

if [ ! -f "${MAPPINGOUT}" ]; then
        log "Mapping MGEs with $(basename ${MGE})"
        $CONDA_PREFIX/bin/blastn -db ${FASTA} -query ${MGE} \
		-strand plus \
		-evalue 1e-03 \
		-outfmt "7 qacc sacc sstart send qlen slen evalue" \
		-task blastn -num_threads ${THREADS} \
		-out $MAPPINGOUT > ${OUTPUT}/tmp/MGE-mapping.err 2>&1
	
else
	warn "MGE-mapping already done. Skipping"
fi

#### RSCRIPT TO REDUCE OVERLAPS
echo "
#!/usr/bin/env Rscript

options(warn=-1)
args = commandArgs(trailingOnly=T)

suppressPackageStartupMessages({
	library(GenomicRanges)
	library(IRanges)
	library(ggbio)
	library(dplyr)
})

# writting functions to be called in apply furtherly

GetMGEName = function(x){
        paste(x[2],
        x[5],
        strsplit(x[1],split = \"::\")[[1]][1],
        x[8],
        sep=\"_\")
}

GetLen4reduced = function(x){
    	sqname = x[1]
    	x[6] = seqlen[sqname]
}

GetReadName = function(x){
    	read = x[1]
    	id = x[7]
    	paste(read,id,sep=\"_\")
}

filtered_data = \"${MAPPINGOUT}.filtered\"
reduced_data =  \"${OUTPUT}/${PREFIX}.MGE_mapping\"

df = read.table(filtered_data)
df\$row = rownames(df)

df\$MGE = apply(df,
        FUN = GetMGEName,
        MARGIN = 1)

df = df[,c(2,3,4,6,9)]
colnames(df) = c(\"seqnames\", \"start\", \"end\", \"seqlength\", \"MGE\")
df\$strand = \"+\"
toPlot = head(df,10)

gr = makeGRangesFromDataFrame(df,
                              seqnames.field=\"seqnames\",
                              start.field=\"start\",
                              end.field=\"end\",
                              strand.field=\"strand\")

tmp = makeGRangesFromDataFrame(toPlot,
                              seqnames.field=\"seqnames\",
                              start.field=\"start\",
                              end.field=\"end\",
                              strand.field=\"strand\")

dfnames = toPlot[,c(1,4)]
dfnames = distinct(dfnames)
seqlen = dfnames\$seqlength
names(seqlen) = dfnames\$seqnames
tmp = GRanges(tmp, seqlengths = seqlen)

dfnames = df[,c(1,4)]
dfnames = distinct(dfnames)
seqlen = dfnames\$seqlength
names(seqlen) = dfnames\$seqnames
toReduce = GRanges(gr, seqlengths = seqlen)

Reduced = reduce(toReduce)
tmp = reduce(tmp)

pdf(paste0(reduced_data, \".viz.pdf\"))

suppressMessages({
autoplot(tmp, aes(fill=\"strand\"), layout = \"karyogram\") +
        scale_fill_manual(values = \"#d95f02\") +
        ggtitle(\"MGE mapping\", subtitle = \"First 10 mappings\") +
        theme(legend.position = \"none\", 
            axis.text.x = element_text(angle=90,vjust=0.5,hjust=0.5))
})

final_df = as.data.frame(Reduced) 

final_df\$seqlen = apply(final_df, 
        FUN = GetLen4reduced,
        MARGIN = 1)

final_df = final_df[,c(1,2,3,6)]

write.table(final_df, reduced_data,
        quote=F, row.names = F, col.names = F)

dev.off()
" > ${OUTPUT}/${PREFIX}_reduce_overlapping_MGEs.R

REDUCED=${OUTPUT}/${PREFIX}.MGE_mapping
RDCD_TMP=${OUTPUT}/tmp/MGE_mapping.reduced
if [ ! -f ${REDUCED} ]; then
        log "Filtering BLAST results"
        # First step, select only those which size is approx. equal to MGE
        # length (i.e., more or less 10% of MGE size)
        cat $MAPPINGOUT | \
        	awk '{ if ($4 - $3 >= $5 * 0.9 && $4 - $3 <= $5 * 1.1){print $0}}' \
        	> ${MAPPINGOUT}.filtered
        # Second, apply the reduce function to remove overlapping
        # alignments
        $CONDA_PREFIX/bin/Rscript \
			${OUTPUT}/${PREFIX}_reduce_overlapping_MGEs.R > /dev/null
else
        warn "Filtered results exist. Skipping"
fi

###### PYTHON SCRIPT TO MERGE UPSTREAM AND DOWNSTREAM FLANKS

echo "
#!/usr/bin/env python

from pyfaidx import Fasta

with Fasta('${RDCD_TMP}.query.upstream') as upstream, \
    Fasta('${RDCD_TMP}.query.downstream') as downstream, \
    open('${OUTPUT}/${PREFIX}_flanks_query.fa','w') as result:
    for a,b in zip(upstream, downstream):
        header = a.name.split(\"::\")[0]
        result.write('>' + header)
        result.write('\n'+str(a))
        result.write(str(b)+'\n')
" > ${OUTPUT}/${PREFIX}_merge_upstream_downstream.py

if [ ! -f ${RDCD_TMP}.upstream ]; then
        log "Retrieving MGE name information (this might take some time)"

        while read line; do
                grep -f <(echo $line | awk -v OFS="\t" '{ print $1, $2, $3 }') \
                ${MAPPINGOUT} | head -n1
        done < ${REDUCED} > ${RDCD_TMP}.mge

	log "Parsing BLAST results"

	#a. hits for which we cannot extract 150bp upstreeam the MGE"
	grep -v "#" ${RDCD_TMP}.mge | \
		awk 'BEGIN{OFS="\t"}{if($3<150){print$0}}' \
		> ${RDCD_TMP}.upstream

        #b. hits for which we cannot extract 150bp downstream the MGE (read ends before it)"
	grep -v "#" ${RDCD_TMP}.mge | \
		awk 'BEGIN{OFS="\t"}{if($4>$6-150){print$0}}' \
		> ${RDCD_TMP}.downstream

	#writing hits that cannot be use (both 1 and 2 are true)"
	grep -v "#" ${RDCD_TMP}.mge | \
		awk 'BEGIN{OFS="\t"}{if($4>$6-150 && $3<150){print$0}}' \
		> ${RDCD_TMP}.anything


	# we have hits that can easily extract the 300bp window

	grep -v "#" ${RDCD_TMP}.mge | \
		grep -v -f ${RDCD_TMP}.upstream | \
		grep -v -f ${RDCD_TMP}.downstream \
		> ${RDCD_TMP}.extract


	# here I am writting the query dfiles. I editted the query name so
	# that it contains: (i) the name of the read the MGE was mapped
	# (ii) the MGE size, and (iii) the MGE name. These three fields are
	# separated by '_' (see the last awk field: $2_$5_$1)

	log "Extracting 300bp flank sequences"
	$CONDA_PREFIX/bin/bedtools getfasta -fi ${FASTA} -name -bed <(cat \
		${RDCD_TMP}.extract | \
		awk 'BEGIN{OFS="\t"}{ print $2, $3-150, $3, $2"_"$5"_"$1}') \
		> ${RDCD_TMP}.query.upstream 2> /dev/null

	#writting downstream flank sequences"
	$CONDA_PREFIX/bin/bedtools getfasta -fi ${FASTA} -name -bed <(cat \
		${RDCD_TMP}.extract | \
		awk 'BEGIN{OFS="\t"}{ print $2, $4, $4+150, $2"_"$5"_"$1}') \
		> ${RDCD_TMP}.query.downstream

	$CONDA_PREFIX/bin/python ${OUTPUT}/${PREFIX}_merge_upstream_downstream.py 

else
	warn "Results already parsed. Skipping"
fi

BLASTOUT=${RDCD_TMP}.blastn

if [ ! -f "${BLASTOUT}" ]; then
        log "Mapping flanks with BLASTn"
        $CONDA_PREFIX/bin/blastn -db ${FASTA} \
		-query ${OUTPUT}/${PREFIX}_flanks_query.fa \
		-evalue 1e-03 \
		-outfmt "7 qacc sacc sstart send length qlen slen evalue" \
		-task megablast -num_threads ${THREADS} -strand plus \
		-out $BLASTOUT > ${OUTPUT}/tmp/blastn.err 2>&1
	
else
	warn "Flanks mapping already done. Skipping"
fi

cp "${BLASTOUT}" "${OUTPUT}/${PREFIX}.flank_mapping"
CLASSIFICATION="${OUTPUT}/${PREFIX}_classification/"

mkdir -p "${CLASSIFICATION}"


##### PYTHON SCRIPT TO GET READS WITH UNFIXED MGES

echo "
#!/usr/bin/env python

import os
import argparse

# this function returns a dictionary with keys being the query and subject name
# pasted, separated by '...'. The values are the start and end of the 
# alignment, the size and name of the MGE that originated the fragment and the 
# size of the subjected read.

# I constructed this in a way that secondary alignments (i.e., alignments 
# sharing both query and subject names) are appended as a list of dictionaries.

def write_feat_dic():
    feat_dic = dict()
    with open('${BLASTOUT}', 'r') as blast:
        for line in blast.readlines():
            if line.startswith('#'):
                continue
            row = line.strip().split('\t')
            key = row[0]+\"...\"+row[1]
            if key not in feat_dic.keys():
                feat_dic[key] = [{'start': row[2],
                                'end': row[3],
                                'MGE_size': (int(row[0].split('_')[1])),
                                'read_size': row[6],
                                'MGE_name': row[0].split('_')[2] }]
            else:
                feat_dic[key].append({'start': row[2],
                                'end': row[3],
                                'MGE_size': (int(row[0].split('_')[1])),
                                'read_size': row[6],
                                'MGE_name': row[0].split('_')[2] })
    return feat_dic

# This function searches for alignments supporting the optional state of the 
# MGEs and writes the name of the subjected read. Note that I added here an 
# important step that remove cases in which the subjected and queried reads are 
# the same. So if a MGE aligned in the read X produced a fragment that aligned 
# on the read X supporting the optional state of this MGE, this will not be 
# considered. We only want cases in which the queried and subjected reads are 
# different. 

def get_unfixed_mges(feat_dic):
    print('#mge_name\tquery_read_name\tread_name\tquery_read_name')
    print('#INTERPRETATION:\n#<flank of this MGE>\t<generated from this read>\t<was mapped with no gaps in this read>\t<this read will be removed>')
    reads_to_remove = []
    with open('${CLASSIFICATION}/${PREFIX}.unfixed_MGEs.readnames','w') as FILEoutRN:
        with open('${CLASSIFICATION}/${PREFIX}.unfixed_MGEs.txt','w') as FILEout:
            # writting header of plottable file
            FILEout.write('queryname\tseqnames\tstart\tend\tseqlength\tMGE\n')
            for k,v in feat_dic.items():
                # checking if there is only one alignment in this read
                if len(v) == 1:
                    query_read_name = k.split(\"_\")[0]
                    end = int(v[0]['end'])
                    start = int(v[0]['start'])
                    gap_size = int(start - end)
                    read_size = int(v[0]['read_size'])
                    if (abs(gap_size) >= 300 * 0.9 
                        and abs(gap_size) <= 300 * 1.1):
                        read_name = k.split('...')[1]
                        # check if subj and query reads are not the same
                        if query_read_name == read_name:
                            print('!!! QUERY AND SUBJECT ARE THE SAME, SKIPPING!!!')
                        else:
                            mge_name = v[0]['MGE_name']
                            print('{}\t{}\t{}\t{}'.format(mge_name,query_read_name, read_name, query_read_name))
                            reads_to_remove.append(query_read_name)
                            # writting file plottable with GRanges
                            FILEout.write('{}\t{}\t{}\t{}\t{}\t{}\n'.format(query_read_name, read_name,start,end,read_size,mge_name))
                            FILEoutRN.write('{}\n'.format(query_read_name))

def get_fixed_mges(feat_dic):
    with open('${CLASSIFICATION}/${PREFIX}.fixed_MGEs.txt','w') as FILEout:
        with open('${CLASSIFICATION}/${PREFIX}.fixed_MGEs.readnames','w') as FILEoutRN:
            # writting header of plottable file
            FILEout.write('queryname\tseqnames\tstart\tend\tseqlength\tMGE\n')
            for k,v in feat_dic.items():
                if len(v) == 2:
                    MGEsize = int(v[0]['MGE_size'])
                    mge_name = v[0]['MGE_name']
                    read_name = k.split('...')[1]
                    read_size = int(v[0]['read_size'])
                    startPLOT = v[0]['start']
                    end = int(v[0]['end'])
                    start = int(v[1]['start'])
                    endPLOT = v[1]['end']
                    gap_size = int(start - end)
                    if (abs(gap_size) >= MGEsize * 0.9 
                        and abs(gap_size) <= MGEsize * 1.1):
                        query_read_name = k.split('...')[0].split(\"_\")[0]
                        mge_name = v[0]['MGE_name']
                        # writting file plottable with GRanges
                        # first alignment...
                        FILEout.write('{}\t{}\t{}\t{}\t{}\t{}\n'.format(query_read_name, read_name,startPLOT,end,read_size,mge_name))
                        # second alignment...
                        FILEout.write('{}\t{}\t{}\t{}\t{}\t{}\n'.format(query_read_name, read_name,start,endPLOT,read_size,mge_name))
                        FILEoutRN.write('{}\n'.format(query_read_name))

def main():
    feat_dic = write_feat_dic()
    get_unfixed_mges(feat_dic)
    get_fixed_mges(feat_dic)

if __name__ == \"__main__\":
    main()
" > ${OUTPUT}/${PREFIX}_get_reads_with_unfixed_MGEs.py

if [ ! -f "${CLASSIFICATION}/${PREFIX}.reads_with_unfixed_MGEs.txt" ]; then
	log "Annotating reads with unfixed MGEs"
	$CONDA_PREFIX/bin/python \
		${OUTPUT}/${PREFIX}_get_reads_with_unfixed_MGEs.py \
		> ${CLASSIFICATION}/reads_classification.info
else
	warn "Reads with unfixed MGEs already annotated. Skipping"
fi

if [ ! -f "${OUTPUT}/${PREFIX}.reads_to_assembly.fastq" ]; then
	log "Generating fastq file with only reads with fixed MGEs"

	filterbyname.sh in="${READS}" \
        names="${CLASSIFICATION}/${PREFIX}.unfixed_MGEs.readnames" \
        out="${OUTPUT}/${PREFIX}.reads_to_assembly.fastq" \
        include=f qin=33 > /dev/null 2>&1

	log "Removing temporary files"
	rm -rf "${OUTPUT}"/tmp
else
	warn "File with reads to assembly already exists. Skipping"
fi

echo -e "\
\033[0;32mAll Done!

  • If you used MGEcatcher to improve your genome assembly, you might use the 
    output file ${PREFIX}.reads_to_assembly.fastq as input for the assembly.

  • If you used MGEcatcher to identify MGE transposition events, you might use
    the output files stored in the ${PREFIX}_classification/ directory.

\e[4mCitation\033[0;32m
If you make use of MGEcatcher in your research, please cite:

FRANCESCHINI-SANTOS, V. H. Impacts of genome instability of Halobacterium salinarum 
NRC-1 in differential gene expression analysis. Honours Thesis (Bachelor’s Degree 
in Biological Sciences) – Faculdade de Filosofia, Ciências e Letras de Ribeirão 
Preto, Universidade de São Paulo. Ribeirão Preto. 2021\033[0m
"